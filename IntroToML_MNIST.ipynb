{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d0f16f-8e9f-440e-9e54-2fb678924e9b",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning: Basic Terms and MNIST Classification\n",
    "\n",
    "Welcome to our Machine Learning class! In this notebook, we introduce key ML terminology such as:\n",
    "\n",
    "- **Dataset**: A collection of examples (data points) used for training and evaluating models.\n",
    "- **Features**: The measurable properties or characteristics used to represent the data.\n",
    "- **Labels**: The target values or classes we want to predict.\n",
    "- **Training**: The process of learning model parameters using the training data.\n",
    "- **Testing**: Evaluating the performance of the model on unseen data.\n",
    "\n",
    "We'll also demonstrate MNIST digit classification using two approaches:\n",
    "\n",
    "1. A **classical machine learning** model (Logistic Regression).\n",
    "2. A **deep learning** model using a **Convolutional Neural Network (CNN)**.\n",
    "\n",
    "This notebook is designed to grab your attention and illustrate the differences between classical algorithms and deep learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff388b5e-82e9-41a9-a5a2-55cd766e179d",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. **Introduction and Setup**: Import necessary libraries and load the MNIST dataset.\n",
    "2. **Classical ML with Logistic Regression**: Preprocess data (flatten images), train a logistic regression classifier, and evaluate it.\n",
    "3. **Deep Learning with CNN**: Preprocess data (reshape images appropriately), build and train a simple CNN, and evaluate its performance.\n",
    "4. **Comparison and Discussion**\n",
    "\n",
    "Let's get started! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43eab95-7f48-4ef0-9770-3d65ef055723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the classical model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# For deep learning with CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# For data loading\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690a390-43b8-4ebf-b998-9da2cf3bb97f",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the MNIST Dataset\n",
    "\n",
    "The MNIST dataset contains 70,000 grayscale images of handwritten digits (0-9). Each image is 28x28 pixels. \n",
    "\n",
    "We split the dataset into a training set (60,000 samples) and a test set (10,000 samples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1c254-5700-4b6b-8ad9-1bfed3a2ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Print the shape of the data\n",
    "print('Training data shape:', x_train.shape)\n",
    "print('Test data shape:', x_test.shape)\n",
    "\n",
    "# Visualize a few examples from the training set\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7f4a7-75b5-484a-9b6a-226a4ae06c1d",
   "metadata": {},
   "source": [
    "## 2. MNIST Classification Using Logistic Regression (Classical ML)\n",
    "\n",
    "Logistic regression is a popular classical ML algorithm for classification. In this example, we'll flatten the 28Ã—28 images into 784-dimensional vectors and then train the classifier. \n",
    "\n",
    "Let's preprocess the data and train the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a2dda-f33d-4e8a-bc99-df1d6c9c6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for logistic regression\n",
    "x_train_flat = x_train.reshape((x_train.shape[0], -1)) / 255.0  # flatten and normalize\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1)) / 255.0\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "logreg = LogisticRegression(solver='saga', max_iter=100, multi_class='multinomial', verbose=1, n_jobs=-1)\n",
    "logreg.fit(x_train_flat, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate\n",
    "y_pred_lr = logreg.predict(x_test_flat)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression Test Accuracy: {accuracy_lr:.4f}\")\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d30b40-40f6-4332-b1a1-71190f244d66",
   "metadata": {},
   "source": [
    "### Visualizing Some Predictions\n",
    "\n",
    "Let's visualize a few examples with their predicted labels from logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca8e16-9103-4838-a63e-8a6bd868dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions from logistic regression\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.title(f\"Predicted: {y_pred_lr[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b735a8b-45fc-4162-8b41-e0b5c2719717",
   "metadata": {},
   "source": [
    "## 3. MNIST Classification Using a Convolutional Neural Network (CNN)\n",
    "\n",
    "Convolutional Neural Networks are a type of deep learning model especially effective for image data. In this section, we will:\n",
    "\n",
    "- Reshape and normalize the MNIST images for a CNN.\n",
    "- Build a simple CNN using TensorFlow/Keras.\n",
    "- Train and evaluate the model.\n",
    "\n",
    "Let's start by preprocessing the data for the CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c87af-1744-41aa-bbce-41f6cb0bd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for CNN\n",
    "x_train_cnn = x_train.reshape(-1, 28, 28, 1) / 255.0  # add channel dimension and normalize\n",
    "x_test_cnn = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "print('Shape for CNN training data:', x_train_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8a1ce-cd91-4b21-93f2-e82da090d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple CNN model using Keras\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb58c9c-4a42-41c0-b2b5-d6bb472efee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN model\n",
    "history = model.fit(x_train_cnn, y_train, epochs=5, batch_size=32,\n",
    "                    validation_split=0.1, verbose=2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test_cnn, y_test, verbose=0)\n",
    "print(f\"CNN Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412800e-372a-42a8-abdd-5e08e84937f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "draw = Image.open(\"path.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb64eb-5fbf-430c-ad3f-705b6ac73c44",
   "metadata": {},
   "source": [
    "### Plotting Training History\n",
    "\n",
    "Let's plot the training and validation accuracy and loss over the epochs to better understand the CNN performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05259a-3e0f-4d2c-b86d-f69124bbd11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4e3a0-e04e-48cb-a3b2-0b84a95522b1",
   "metadata": {},
   "source": [
    "## 4. Conclusion and Discussion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "- Introduced key machine learning terms.\n",
    "- Demonstrated MNIST classification with a classical ML algorithm (logistic regression).\n",
    "- Built and trained a Convolutional Neural Network (CNN) for the same task, observing higher accuracy.\n",
    "\n",
    "This comparative example highlights how deep learning techniques (like CNNs) can better capture spatial hierarchies in image data compared to classical ML methods. \n",
    "\n",
    "Feel free to tweak hyperparameters, change architectures, or explore further on your own. Happy learning! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
